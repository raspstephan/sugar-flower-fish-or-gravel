{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime as datetime\n",
    "from netCDF4 import num2date, date2num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading classification csv file from zooniverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classfile_in = '../zooniverse_raw/sugar-flower-fish-or-gravel-classifications_18_12_16.csv'\n",
    "subject_in = '../zooniverse_raw/sugar-flower-fish-or-gravel-subjects_18_11_05.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions from https://github.com/zooniverse/Data-digging/blob/master/example_scripts/astronomy_rewind/workflow1to2.py\n",
    "\n",
    "def JSONParser(data):\n",
    "    \"\"\"call json.loads\"\"\"\n",
    "    return json.loads(data)\n",
    "\n",
    "\n",
    "def load_classifications(filename, json_columns=None):\n",
    "    \"\"\"\n",
    "    Load classifications into pandas dataframe.\n",
    "    Some columns of the csv are embedded json and need special parsing.\n",
    "    \"\"\"\n",
    "    json_columns = json_columns or ['metadata', 'annotations', 'subject_data']\n",
    "    converters = {i: JSONParser for i in json_columns}\n",
    "\n",
    "    return pd.read_csv(filename, converters=converters)\n",
    "\n",
    "def unpack(series):\n",
    "    \"\"\"\n",
    "    Return the first value in a series.\n",
    "    All annotations values are lists because of a few multiple tasks.\n",
    "    The second multiple task always has the value of 'None of the above'\n",
    "    (For this dataset!)\n",
    "    \"\"\"\n",
    "    return [a[0] for a in series]\n",
    "\n",
    "\n",
    "def parse_classifications(filename,**kwarg):\n",
    "    \"\"\"\n",
    "    Load classifications and datamunge annotations column.\n",
    "    \"\"\"\n",
    "    data = load_classifications(filename,**kwarg)\n",
    "\n",
    "    # Only need the first item in the annotations list of json objects\n",
    "    data['annotations'] = unpack(data['annotations'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_spent(obj):\n",
    "    from datetime import timedelta, datetime\n",
    "    time_fmt='%Y-%m-%dT%H:%M:%S.%fZ'\n",
    "    start=datetime.strptime(obj[11]['started_at'],time_fmt)\n",
    "    stop=datetime.strptime(obj[11]['finished_at'],time_fmt)\n",
    "    d=stop-start\n",
    "    if d.total_seconds() > 3600*10:\n",
    "        d=0\n",
    "        return d\n",
    "    else:\n",
    "        return d.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_data = parse_classifications(classfile_in,json_columns=['metadata', 'annotations', 'subject_data']); classification_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_data[\"created_at\"] = [datetime.datetime.strptime(classification_data.created_at[i], \"%Y-%m-%d %H:%M:%S UTC\") for i in classification_data.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first index of data after specific date\n",
    "ind = np.min(np.where(classification_data.created_at > datetime.datetime(2018,10,2))[0]); ind\n",
    "classification_data = classification_data.iloc[ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_data.annotations[classification_data.index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_data.metadata[classification_data.index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time spend on each classification\n",
    "classification_data['time_spent'] = [get_time_spent(row) for row in classification_data.itertuples()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_user_dict(user_dic,user_id, dic):\n",
    "    # user existiert bereits\n",
    "    if user_dic.get(user_id) != None:\n",
    "        for key in dic.keys():\n",
    "            if user_dic[user_id].get(key) != None:\n",
    "                old_value = user_dic[user_id][key]\n",
    "                new_value = old_value+dic[key]\n",
    "                user_dic[user_id][key]=new_value\n",
    "            else:\n",
    "                user_dic[user_id][key]=dic[key]\n",
    "    else:\n",
    "        user_dic[user_id] = dic\n",
    "    return user_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_stat = {}\n",
    "for u,user_classifications in classification_data.groupby('user_name'):\n",
    "    pattern_types = user_classifications.annotations\n",
    "    labels=np.array([])\n",
    "    for classification in pattern_types:\n",
    "        labels = np.append(labels,[value['tool'] for value in classification['value']])\n",
    "    [nb_sugar, nb_flower, nb_fish, nb_gravel] = np.bincount(labels.astype(int),minlength=4)\n",
    "    time_spent = user_classifications.time_spent.sum()\n",
    "    user_stat = update_user_dict(user_stat, u, {'images_seen': len(user_classifications), 'fish': nb_fish,'gravel': nb_gravel, 'flower': nb_flower, 'sugar':nb_sugar, 'time_spent': time_spent})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_user = pd.DataFrame.from_dict(user_stat,orient='index')\n",
    "DF_user['labels_done'] = DF_user.iloc[:,[1,2,3,4]].sum(axis=1)\n",
    "DF_user.sort_values('labels_done',inplace=True)\n",
    "DF_user.head()\n",
    "DF_user.drop(DF_user.index[DF_user.labels_done < 200],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "sns.set_style('ticks')\n",
    "fig=plt.figure()\n",
    "p1=(DF_user.iloc[:,[1,2,3,4]]).plot(kind='bar', figsize=(15,6), stacked=True)#DF_user.iloc[:,[0]].plot(kind='bar',ax=p1.axes, alpha=0.4)\n",
    "p1.set_ylabel('labels')\n",
    "#plt.hlines(500,-1,70)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.gcf().set_dpi(300)\n",
    "plt.savefig('/Users/haukeschulz/Desktop/CloudClassificationDayStats_preliminary.png',transparent=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "sns.set_style('ticks')\n",
    "titles=['Do you like fish?', 'Flower power', 'Sweetness-factor', 'Just Gravel']\n",
    "for p,pattern in enumerate(['fish','flower','sugar','gravel']):\n",
    "    plt.figure()\n",
    "    pattern_percentage = pattern+'_percentage'\n",
    "    DF_user[pattern_percentage] = DF_user[pattern]/DF_user.labels_done*100\n",
    "    p1=DF_user.sort_values(pattern_percentage)[pattern_percentage].plot(kind='bar', figsize=(10,6), color='darkblue')\n",
    "    t=p1.set_ylabel('{} labels relative to your total labels [%]'.format(pattern))\n",
    "    #p1.set_title('Do you like {}?'.format(pattern))\n",
    "    p1.set_title(titles[p])\n",
    "    plt.gcf().set_dpi(300)\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "sns.set_style('ticks')\n",
    "DF_user['images_per_minute'] = 60/(DF_user.time_spent/DF_user.images_seen)\n",
    "p1=DF_user.sort_values('images_per_minute').images_per_minute.plot(kind='bar', figsize=(10,5), stacked=True, color='darkblue')\n",
    "#DF_user.iloc[:,[0]].plot(kind='bar',ax=p1.axes, alpha=0.4)\n",
    "t=p1.set_ylabel('images per minute')\n",
    "p1.set_title('Speed')\n",
    "plt.gcf().set_dpi(300)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "sns.set_style('ticks')\n",
    "p1=(DF_user.sort_values('time_spent').time_spent/3600).plot(kind='bar', figsize=(10,5), stacked=True, color='darkblue')\n",
    "#DF_user.iloc[:,[0]].plot(kind='bar',ax=p1.axes, alpha=0.4)\n",
    "t=p1.set_ylabel('time spent (hours)')\n",
    "p1.set_title('Time spent')\n",
    "plt.gcf().set_dpi(300)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject set statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_data = load_classifications(subject_in)\n",
    "subject_data = subject_data.set_index('subject_id'); subject_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_name = {60811:'BCO_DJF_Aqua',60812:'BCO_DJF_Terra',60813: 'BCO_MAM_Aqua',\\\n",
    "                 60814: 'BCO_MAM_Terra',60815:'R2_DJF_Aqua',60816:'R2_DJF_Terra',\\\n",
    "                 60817:'R3_DJF_Aqua', 60818:'R3_DJF_Terra',60819:'R3_SON_Aqua',\\\n",
    "                 60835: 'R3_SON_Terra'}\n",
    "for s, subject_set in subject_data.groupby('subject_set_id'):\n",
    "    try:\n",
    "        print(subjects_name[s])\n",
    "        print(len(subject_set),subject_set.classifications_count.sum(),\\\n",
    "              len(subject_set.classifications_count.nonzero()[0]),\\\n",
    "              np.round(len(subject_set.classifications_count.nonzero()[0])/len(subject_set)*100,1))\n",
    "        print('maximum number of classifications per image: {}'.format(subject_set.classifications_count.max()))\n",
    "    except KeyError:\n",
    "        print('Subset {} not of interest'.format(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of pattern within region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dict(region_dic,region_id, dic):\n",
    "    # user existiert bereits\n",
    "    if region_dic.get(region_id) != None:\n",
    "        for key in dic.keys():\n",
    "            if region_dic[region_id].get(key) != None:\n",
    "                old_value = region_dic[region_id][key]\n",
    "                new_value = old_value+dic[key]\n",
    "                region_dic[region_id][key]=new_value\n",
    "            else:\n",
    "                region_dic[region_id][key]=dic[key]\n",
    "    else:\n",
    "        region_dic[region_id] = dic\n",
    "    return region_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_stat = {}\n",
    "for e,entry in enumerate(classification_data.iterrows()):\n",
    "    nb_fish = nb_gravel = nb_flower = nb_sugar = 0\n",
    "    subject_id = entry[1].subject_ids\n",
    "    workflow_c_id = entry[1].workflow_id\n",
    "    pattern_types = entry[1].annotations\n",
    "    labels = [value['tool'] for value in pattern_types['value']]\n",
    "    [nb_sugar, nb_flower, nb_fish, nb_gravel] = np.bincount(labels,minlength=4)\n",
    "    try:\n",
    "        ind = np.where(subject_id == subject_data.index.values)[0][0]\n",
    "        subset_id = subject_data.subject_set_id.values[ind]\n",
    "        workflow_id = subject_data.workflow_id.values[ind]\n",
    "        if workflow_c_id == np.float(8073):\n",
    "            try:\n",
    "                region_name = subjects_name[subset_id]\n",
    "                region_stat = update_dict(region_stat, region_name, {'fish': nb_fish,'gravel': nb_gravel, 'flower': nb_flower, 'sugar':nb_sugar})\n",
    "            except KeyError:\n",
    "                continue\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = np.asarray(pd.DataFrame.from_dict(region_stat)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.DataFrame.from_dict(region_stat,orient='index')\n",
    "x['region'] = [0,0,1,1,2,2,3,3,4,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_result = {}\n",
    "for region, region_grp in x.groupby('region'):\n",
    "    region_result[region_grp.index.values[0][:-5]] = region_grp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_stat2 = region_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_column_names = ['fish', 'flower','gravel','sugar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(total_column_names,total)\n",
    "sns.despine(offset=10)\n",
    "plt.gcf().set_dpi(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=pd.DataFrame.from_dict(region_stat2,orient='columns')\n",
    "DF.drop('region',inplace=True)\n",
    "\n",
    "def make_autopct(values):\n",
    "    def my_autopct(pct):\n",
    "        total = sum(values)\n",
    "        val = int(round(pct*total/100.0))\n",
    "        return '{p:.2f}%  ({v:d})'.format(p=pct,v=val)\n",
    "    return my_autopct\n",
    "\n",
    "DF.plot(kind='pie',figsize=(15,22),subplots=True,layout=(3, 2),labels=None,legend=None,autopct='%1.1f%%',yticks=None)\n",
    "ax=plt.gca()\n",
    "sns.despine(offset=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or just another layout of the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=pd.DataFrame.from_dict(region_stat,orient='index')\n",
    "\n",
    "p=DF.plot(kind='bar',figsize=(20,10),stacked=True)\n",
    "p.set_ylabel('labels')\n",
    "sns.despine(offset=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above figure includes both, the practice workflow and the full dataset workflow.\n",
    "\n",
    "It looks like there is a difference between Aqua and Terra overpasses. Flowers are always less during Aqua than during Terra!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['total'] = DF.iloc[:,[0,1,2,3]].sum(axis=1); DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the relative differences between the Aqua and Terra data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.loc['BCO_DJF_diff'] = DF.iloc[0,[0,1,2,3]]/DF.iloc[0,4]*100-DF.iloc[1,[0,1,2,3]]/DF.iloc[1,4]*100\n",
    "DF.loc['BCO_MAM_diff'] = DF.iloc[2,[0,1,2,3]]/DF.iloc[2,4]*100-DF.iloc[3,[0,1,2,3]]/DF.iloc[3,4]*100\n",
    "DF.loc['R2_DJF_diff'] = DF.iloc[4,[0,1,2,3]]/DF.iloc[4,4]*100-DF.iloc[5,[0,1,2,3]]/DF.iloc[5,4]*100\n",
    "DF.loc['R3_DJF_diff'] = DF.iloc[6,[0,1,2,3]]/DF.iloc[6,4]*100-DF.iloc[7,[0,1,2,3]]/DF.iloc[7,4]*100\n",
    "DF.loc['R3_SON_diff'] = DF.iloc[8,[0,1,2,3]]/DF.iloc[8,4]*100-DF.iloc[9,[0,1,2,3]]/DF.iloc[9,4]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=DF.loc[['BCO_DJF_diff','BCO_MAM_diff','R2_DJF_diff','R3_DJF_diff','R3_SON_diff'],['fish','gravel','flower','sugar']].plot(kind='bar',figsize=(12,7),stacked=False)\n",
    "p.set_ylabel('Aqua-Terra (%)')\n",
    "sns.despine(offset=20)\n",
    "plt.gcf().set_dpi(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the difference between the overpasses is quite obvious. However, the *flower* classifications are always less during Aqua overpasses, but for the region BCO in DJF, where there is no significant change at all.\n",
    "( Check if that changes when the practice dataset is excluded )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_stat = {}\n",
    "for e,entry in enumerate(classification_data.iterrows()):\n",
    "    if entry[1].workflow_id == np.float(8072): #Practical workflow\n",
    "        nb_fish = nb_gravel = nb_flower = nb_sugar = 0\n",
    "        subject_id = entry[1].subject_ids\n",
    "        pattern_types = entry[1].annotations\n",
    "        labels = [value['tool'] for value in pattern_types['value']]\n",
    "        [nb_sugar, nb_flower, nb_fish, nb_gravel] = np.bincount(labels,minlength=4)\n",
    "        try:\n",
    "            ind = np.where(subject_id == subject_data.index.values)[0][1] #<-- 0: BCO_DJF_Aqua, 1: practice 50 images\n",
    "            subset_id = subject_data.subject_set_id.values[ind]\n",
    "            if subset_id == np.float(60902): #check again for savety\n",
    "                try:\n",
    "                    image_name = subject_id\n",
    "                    image_stat = update_dict(image_stat, image_name, {'fish': nb_fish,'gravel': nb_gravel, 'flower': nb_flower, 'sugar':nb_sugar})\n",
    "                except KeyError:\n",
    "                    continue\n",
    "                #image_stat[e] = {'fish': nb_fish,'gravel': nb_gravel, 'flower': nb_flower, 'sugar':nb_sugar}\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "practical_image_DF = pd.DataFrame.from_dict(image_stat); practical_image_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=practical_image_DF.plot(kind='pie',layout=(12,5), legend=None, subplots=True,figsize=(30,50));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
